{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-14T23:33:56.926660Z",
     "iopub.status.busy": "2025-03-14T23:33:56.926376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (60000, 28, 28, 1), Labels: (60000,)\n",
      "Testing Data: (10000, 28, 28, 1), Labels: (10000,)\n",
      "Epoch 1/10 - Loss: 2.1132 - Accuracy: 0.2250\n",
      "Epoch 2/10 - Loss: 0.8280 - Accuracy: 0.7440\n",
      "Epoch 3/10 - Loss: 0.5409 - Accuracy: 0.8450\n",
      "Epoch 4/10 - Loss: 0.4465 - Accuracy: 0.8700\n",
      "Epoch 5/10 - Loss: 0.3670 - Accuracy: 0.8900\n",
      "Epoch 6/10 - Loss: 0.3148 - Accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct #using struct to unpacj binary data from mnist dataset\n",
    "\n",
    "#22k-4501\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols, 1) / 255.0\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        _, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "train_images = load_mnist_images(\"/kaggle/input/mnist-dataset/train-images.idx3-ubyte\")\n",
    "train_labels = load_mnist_labels(\"/kaggle/input/mnist-dataset/train-labels.idx1-ubyte\")\n",
    "test_images = load_mnist_images(\"/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte\")\n",
    "test_labels = load_mnist_labels(\"/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte\")\n",
    "print(f\"Training Data: {train_images.shape}, Labels: {train_labels.shape}\")\n",
    "print(f\"Testing Data: {test_images.shape}, Labels: {test_labels.shape}\")\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Avoid overflow\n",
    "    return exp_x / exp_x.sum(axis=-1, keepdims=True)\n",
    "def cross_entropy_loss(predictions, label):\n",
    "    return -np.log(predictions[label] + 1e-9)  \n",
    "class ConvLayer:\n",
    "    def __init__(self, num_filters, filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) * 0.1\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w, _ = input.shape\n",
    "        output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "\n",
    "        for i in range(output.shape[0]):\n",
    "            for j in range(output.shape[1]):\n",
    "                region = input[i:i+self.filter_size, j:j+self.filter_size, 0]\n",
    "                for f in range(self.num_filters):\n",
    "                    output[i, j, f] = np.sum(region * self.filters[f])\n",
    "        \n",
    "        return np.maximum(output, 0)  # ReLU Activation\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        d_filters = np.zeros_like(self.filters)\n",
    "\n",
    "        for i in range(d_out.shape[0]):\n",
    "            for j in range(d_out.shape[1]):\n",
    "                region = self.last_input[i:i+self.filter_size, j:j+self.filter_size, 0]\n",
    "                for f in range(self.num_filters):\n",
    "                    d_filters[f] += region * d_out[i, j, f]\n",
    "        self.filters -= lr * d_filters  \n",
    "        return d_out \n",
    "        \n",
    "class MaxPoolLayer:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input\n",
    "        h, w, num_filters = input.shape\n",
    "        output = np.zeros((h // self.size, w // self.size, num_filters))\n",
    "        self.max_indices = np.zeros_like(input, dtype=bool)\n",
    "\n",
    "        for i in range(output.shape[0]):\n",
    "            for j in range(output.shape[1]):\n",
    "                region = input[i*self.size:(i+1)*self.size, j*self.size:(j+1)*self.size]\n",
    "                max_value = np.max(region, axis=(0, 1))\n",
    "                output[i, j] = max_value\n",
    "                self.max_indices[i*self.size:(i+1)*self.size, j*self.size:(j+1)*self.size] = (region == max_value)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, d_out):\n",
    "        d_input = np.zeros_like(self.last_input)\n",
    "        for i in range(d_out.shape[0]):\n",
    "            for j in range(d_out.shape[1]):\n",
    "                d_input[i*self.size:(i+1)*self.size, j*self.size:(j+1)*self.size] = d_out[i, j] * self.max_indices[i*self.size:(i+1)*self.size, j*self.size:(j+1)*self.size]\n",
    "        return d_input\n",
    "class FullyConnected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.1\n",
    "        self.biases = np.zeros(output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.last_input = input.flatten()\n",
    "        return softmax(np.dot(self.last_input, self.weights) + self.biases)\n",
    "\n",
    "    def backward(self, d_out, lr):\n",
    "        d_w = np.outer(self.last_input, d_out)\n",
    "        d_b = d_out\n",
    "        d_input = np.dot(d_out, self.weights.T)\n",
    "\n",
    "        self.weights -= lr * d_w\n",
    "        self.biases -= lr * d_b\n",
    "\n",
    "        return d_input.reshape(self.last_input.shape)\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvLayer(8, 3)\n",
    "        self.conv2 = ConvLayer(8, 3)\n",
    "        self.pool = MaxPoolLayer(2)\n",
    "        sample_input = np.zeros((28, 28, 1))\n",
    "        x = self.conv1.forward(sample_input)\n",
    "        x = self.conv2.forward(x)\n",
    "        x = self.pool.forward(x)\n",
    "        self.flattened_shape = x.shape \n",
    "        flattened_size = np.prod(self.flattened_shape)\n",
    "\n",
    "        self.fc = FullyConnected(flattened_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1.forward(x)\n",
    "        x = self.conv2.forward(x)\n",
    "        x = self.pool.forward(x)\n",
    "        return self.fc.forward(x)\n",
    "\n",
    "    def backward(self, d_out, lr=0.005):\n",
    "        d_out = self.fc.backward(d_out, lr)\n",
    "        d_out = d_out.reshape(self.flattened_shape)\n",
    "        d_out = self.pool.backward(d_out)\n",
    "        d_out = self.conv2.backward(d_out, lr)\n",
    "        d_out = self.conv1.backward(d_out, lr)\n",
    "def train(model, train_X, train_y, epochs=1, lr=0.005):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        for i in range(len(train_X)):\n",
    "            x, y = train_X[i], train_y[i]\n",
    "            out = model.forward(x)\n",
    "            loss += cross_entropy_loss(out, y)\n",
    "            correct += (np.argmax(out) == y)\n",
    "\n",
    "            d_out = out\n",
    "            d_out[y] -= 1  \n",
    "            model.backward(d_out, lr)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {loss / len(train_X):.4f} - Accuracy: {correct / len(train_X):.4f}\")\n",
    "\n",
    "model = CNN()\n",
    "train(model, train_images[:1000], train_labels[:1000], epochs=10, lr=0.005)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(test_images[:200])):\n",
    "    pred = np.argmax(model.forward(test_images[i]))\n",
    "    correct += (pred == test_labels[i])\n",
    "\n",
    "print(f\"Test Accuracy: {correct / 200:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 102285,
     "sourceId": 242592,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
